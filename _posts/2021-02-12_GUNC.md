---
layout: single
title: "Clade separation score in GUNC"
date: 2021-02-12
---

_Luis Pedro Coelho_

_Initial note_: For the full story, see the [GUNC
preprint](https://www.biorxiv.org/content/10.1101/2020.12.16.422776v1). Luis
helped a bit developing the ideas behind the current iteration of the CSS and
wrote this blogpost, but most of the work was done by Askarbek and Anthony.

Let's say you have a metagenome-assembled genome (MAG) and want to check if
it's good. What should you do? Use
[checkM](https://ecogenomics.github.io/CheckM/)! Let's say you already used
CheckM and want even more assurances. In particular, you want to be sure that
the genome is likely free of contamination (contain only sequence from a single
real genome); what can you do?

You could use taxonomic classification of the genes in the genome. In the ideal
case, this would solve your problems directly: if all the genes are classified
as coming from the same source, then this is your genome; otherwise, you have
contamination. Unfortunately, this ideal case only works _if there are no
errors in the prediction_. In practice, taxonomic predictions are imperfect, so
what can you do?


How can you tell if you have genes from two taxa (_A_ &amp; _B_) because (1)
your so-called genome is actually a mixture of _A_ and _B_ or (2) the predictor
is not perfect and gets confused between the two? One intuition is to look at
the pattern of errors. A MAG is, effectively, a bin (_i.e._, a group) of
contigs and each contig will have a number of genes: if _A_ and _B_ are
randomly spread out, then this does not provide any evidence for contamination:

![Errors are spread: no contamination]({{ site.baseurl }}/assets/2021-02-12-GUNC/spread-out.svg)


However, if _A_ and _B_ follow contig boundaries, then this is likely
contamination:

![Errors are concentrated: contamination is likely]({{ site.baseurl }}/assets/2021-02-12-GUNC/concentrated.svg)

This assumes that most errors in MAGs are binning errors (_i.e._, the
individual contigs are good, but they are grouped incorrectly), which seems to
be empirically true.

If all you care about is getting the intuition behind a tool, you can stop
here, but now I want to show you how we went from this intuition into the
_Clade Separation Score_ implemented in the tool.

The first idea was to think in terms of _information_: how much information
about the taxonomic is provided by the contig information? This naturally leads
to thinking about conditional entropy, so that we could define the first
version of our metric as a normalized form of it:

<img src="http://latex.codecogs.com/gif.latex?\\C_1 = 1 - \frac{H(T|C)}{H(T)}" />.

Where _H(T|C)_ is the entropy of the taxonomic assignments, given the contig
assignments; normalized by _H(T)_ the overall taxonomic entropy. If there is no
relationship, then _H(T|C) = H(T)_, so _C₁ = 0_ (we subtract from 1 to make
larger numbers denote more evidence of contatimation). On the other hand, if
the taxonomic assignments perfectly follow the contigs, then _H(T|C) = 0_ and
_C₁ = 1_.

Great! So, is this what we used in the paper? **No**.

The problem is that we cannot actually know the true value of _H(T|C)_ (or even
_H(T)_, although that is less problematic). We can estimate it from data,
though. The simplest way is to use the _plugin estimators_:

<img src="http://latex.codecogs.com/gif.latex?\\\hat{H}(T|C) = - \sum_c \sum_t \frac{a_{ct}}{N} \log \frac{a_{ct}}{N_c}" />.

In the above, _N_ is the total number of genes and <img
src="http://latex.codecogs.com/gif.latex?\\N_c" /> is the number of genes in
the contig _c_. The problem is that <em>these entropy estimators are biased and
<strong>heavily biased when <img
src="http://latex.codecogs.com/gif.latex?\\N_c" /> is generally
small</strong></em>. This is a known problem (Basharin, 1959) and there are
better estimators.

Maybe a thought experiment would illustrate the problem: imagine you have a
genome whose taxonomic assignments are exactly evenly split between two taxa
(_A_ and _B_) and without any relationship between the contig structure and the
taxonomic assignments. Imagine, however, that the genome is heavily fragmented
(many short contigs). In this case, even though _H(T|C) = H(T)_, the estimated
versions would be biased: _Ĥ(T|C) « Ĥ(T)_. In particular, any contigs with a
single gene would be contributing zero to the sum above. Contigs with 2 genes
would also show up as pure _A_ or pure _B_ contigs half the time (randomly).

There has been some work to tackle similar issues when evaluating clustering
results (Nguyen et al., 2009; other too), but our problem is slightly
different: the fragmentation of the genome is something that we cannot do
anything about, but should not contribute any evidence of contamination.

Our first idea was to use a more robust estimator than the plugin estimator
above. This did seem to improve the results, but there was another idea that
was both conceptually very simple and easy to implement: we kept the plugin
estimator for _Ĥ(T|C)_ but also compute the same formula for a random
assignment of genes to contigs that preserves the distribution of contig sizes.
Conceptually, we perfom a permutation test: we repeatedly reassign the taxonomic
genes labels across all the genes in the genome and compute the average value
of the plugin estimator. Because of the bias discussed above, for fragmented
genomes, this value is less than _Ĥ(T)_, even though _H(T|C) = H(T)_. This
average we call _Ĥ(T|R)_, leading to 

<div align=center>
<img src="http://latex.codecogs.com/gif.latex?\\C = 1 - \frac{\hat{H}(T|C)}{\hat{H}(T|R)}" />.
</div>

In practice, we do not need to actually perform the permutation test and can
save ourselves the computational expense of multiple randomizations to get a
mean value. In fact, another advantage of this approach is that it's very easy
to compute the closed form expression for the expected value and this is what
we use in the released version of the tool‡.

## References

-  Basharin GP. On a statistical estimate for the entropy of a sequence of
   independent random variables. Theory of Probability & Its Applications.
   1959;4(3):333-6. — You know you are doing real math when the papers you are
   reading have _been translated from Russian_.

- Nguyen XV, Epps J, Bailey J. Information theoretic measures for clusterings
  comparison: is a correction for chance necessary?. ICML 2009

‡ Technically, we needed to assume contigs are being sampled _with replacement_
whereas doing permutations is sampling _without replacement_, but this does not
meaningfully affect the outcome.

